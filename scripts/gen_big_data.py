import csv
import random
import os
import time
from datetime import datetime, timedelta

def generate_big_data(file_path, target_size_gb=1):
    # 1. Cáº¤U HÃŒNH Dá»® LIá»†U MáºªU (Äá»ƒ mapping khá»›p vá»›i products.json)
    emails = [f"user_{i}@gmail.com" for i in range(1, 1001)]
    product_ids = [f"p_00{i}" for i in range(1, 4)] # p_001, p_002, p_003
    start_date = datetime(2025, 1, 1)

    # TÃ­nh toÃ¡n kÃ­ch thÆ°á»›c
    target_bytes = target_size_gb * 1024 * 1024 * 1024
    current_bytes = 0
    row_count = 0
    
    # 2. KHá»I Táº O FILE
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    
    print(f"ğŸš€ Äang khá»Ÿi táº¡o file {target_size_gb}GB táº¡i: {file_path}")
    start_time = time.time()

    with open(file_path, 'w', newline='') as f:
        writer = csv.writer(f)
        # Viáº¿t Header
        writer.writerow(["order_id", "customer_email", "product_id", "qty", "date"])
        
        # 3. GHI THEO BATCH (Äá»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ ghi Ä‘Ä©a)
        batch_size = 100000 
        while current_bytes < target_bytes:
            batch_data = []
            for _ in range(batch_size):
                row_count += 1
                # Táº¡o dÃ²ng dá»¯ liá»‡u ngáº«u nhiÃªn
                order_id = row_count
                email = random.choice(emails)
                p_id = random.choice(product_ids)
                qty = random.randint(1, 5)
                # Random ngÃ y trong nÄƒm 2025
                dt = start_date + timedelta(days=random.randint(0, 364), seconds=random.randint(0, 86400))
                date_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                
                batch_data.append([order_id, email, p_id, qty, date_str])
            
            writer.writerows(batch_data)
            
            # Cáº­p nháº­t dung lÆ°á»£ng hiá»‡n táº¡i
            current_bytes = f.tell()
            progress = (current_bytes / target_bytes) * 100
            elapsed = time.time() - start_time
            print(f"â³ ÄÃ£ ghi: {current_bytes/(1024**3):.2f} GB ({progress:.1f}%) - Time: {elapsed:.1f}s", end='\r')

    print(f"\nâœ… HoÃ n thÃ nh!")
    print(f"ğŸ“Š Tá»•ng sá»‘ dÃ²ng: {row_count:,}")
    print(f"â±ï¸ Thá»i gian thá»±c hiá»‡n: {time.time() - start_time:.1f} giÃ¢y")

if __name__ == "__main__":
    # Vá»›i má»¥c Ä‘Ã­ch há»c táº­p, 1GB (~15 triá»‡u dÃ²ng) lÃ  Ä‘á»§ Ä‘á»ƒ tháº¥y sá»©c máº¡nh cá»§a Chunking
    path = "data/raw/transactions_big.csv"
    generate_big_data(path, target_size_gb=1)